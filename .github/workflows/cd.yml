name: CD â€” Build & Deploy to GKE

on:
  workflow_run:
    workflows: ["CI - Main Branch"]
    branches: [main]
    types:
      - completed
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  LOCATION: ${{ secrets.GCP_REGION }}
  REPO: ${{ secrets.ARTIFACT_REPO }}
  IMAGE_NAME: ${{ secrets.IMAGE_NAME }}
  K8S_NAMESPACE: ${{ secrets.K8S_NAMESPACE }}

jobs:
  build-and-deploy:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies (MLflow)
        run: |
          python -m pip install --upgrade pip
          pip install mlflow

      - name: Fetch best model from MLflow
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_EXPERIMENT_NAME: ${{ secrets.MLFLOW_EXPERIMENT_NAME }}
        run: |
          echo "Fetching best model from MLflow experiment..."
          python <<'PYCODE'
          import mlflow
          from mlflow.tracking import MlflowClient
          import os, shutil

          client = MlflowClient()
          experiment_name = os.getenv("MLFLOW_EXPERIMENT_NAME")
          experiment = client.get_experiment_by_name(experiment_name)
          if not experiment:
              raise SystemExit(f"Experiment '{experiment_name}' not found in MLflow.")
          
          experiment_id = experiment.experiment_id
          print(f"Searching best model from experiment: {experiment_name} (ID: {experiment_id})")

          results = mlflow.search_logged_models(
              experiment_ids=[experiment_id],
              order_by=[{"field_name": "metrics.accuracy", "ascending": False}],
              max_results=1,
              output_format="list"
          )

          if not results:
              raise SystemExit("No logged models found in this experiment.")

          best_model = results[0]
          print(f"Best model ID: {best_model.model_id}")
          print(f"Accuracy: {best_model.metrics[0].value}")

          model_uri = f"models:/{best_model.model_id}"
          output_dir = "app/models"
          if os.path.exists(output_dir):
              shutil.rmtree(output_dir)
          os.makedirs(output_dir, exist_ok=True)

          print(f"Downloading model from {model_uri}...")
          mlflow.artifacts.download_artifacts(artifact_uri=model_uri, dst_path=output_dir)
          print(f"Saved best model to '{output_dir}/'")
          PYCODE
          
      - name: List downloaded model files
        run: |
          echo "Contents of app/models directory:"
          ls -R app/models
          
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_KEY_JSON }}

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud --quiet auth configure-docker ${LOCATION}-docker.pkg.dev

      - name: Set image environment variables
        run: |
          IMAGE_TAG=${GITHUB_SHA::8}
          echo "IMAGE_TAG=${IMAGE_TAG}" >> $GITHUB_ENV
          IMAGE_FULL_NAME=${LOCATION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:${IMAGE_TAG}
          echo "IMAGE_FULL_NAME=${IMAGE_FULL_NAME}" >> $GITHUB_ENV
          IMAGE_LATEST=${LOCATION}-docker.pkg.dev/${PROJECT_ID}/${REPO}/${IMAGE_NAME}:latest
          echo "IMAGE_LATEST=${IMAGE_LATEST}" >> $GITHUB_ENV

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./app
          file: ./app/Dockerfile
          push: true
          tags: |
            ${{ env.IMAGE_FULL_NAME }}
            ${{ env.IMAGE_LATEST }}

      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ secrets.GKE_CLUSTER }}
          location: ${{ secrets.GCP_REGION }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Apply ConfigMap for FastAPI
        env:
          K8S_NAMESPACE: ${{ env.K8S_NAMESPACE }}
        run: |
          echo "Creating or updating ConfigMap 'iris-fastapi-config'..."
          kubectl create configmap iris-fastapi-config \
            --from-literal=MODEL_PATH=/app/models/model.joblib \
            --from-literal=ENV=production \
            --namespace ${K8S_NAMESPACE:-default} \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy to GKE
        env:
          IMAGE_FULL_NAME: ${{ env.IMAGE_FULL_NAME }}
          K8S_NAMESPACE: ${{ env.K8S_NAMESPACE }}
        run: |
          echo "Deploying image ${IMAGE_FULL_NAME} to namespace ${K8S_NAMESPACE:-default}"

          # Apply manifests first (creates Deployment/Service if missing)
          kubectl apply -f app/k8s/deployment.yaml --namespace ${K8S_NAMESPACE:-default}
          kubectl apply -f app/k8s/service.yaml --namespace ${K8S_NAMESPACE:-default}

          # Update the image in the running deployment
          kubectl set image deployment/iris-fastapi iris-fastapi=${IMAGE_FULL_NAME} --namespace ${K8S_NAMESPACE:-default}

          # Wait for rollout completion
          kubectl rollout status deployment/iris-fastapi --namespace ${K8S_NAMESPACE:-default} --timeout=300s
      
      - name: Apply Horizontal Pod Autoscaler
        env:
          K8S_NAMESPACE: ${{ env.K8S_NAMESPACE }}
        run: |
          echo "Applying Horizontal Pod Autoscaler in namespace ${K8S_NAMESPACE:-default}"
          kubectl apply -f app/k8s/hpa.yaml --namespace ${K8S_NAMESPACE:-default}
      
      - name: Verify deployment & HPA status
        env:
          K8S_NAMESPACE: ${{ env.K8S_NAMESPACE }}
        run: |
          echo "Deployment Status:"
          kubectl rollout status deployment/iris-fastapi --namespace ${K8S_NAMESPACE:-default}
          echo "HPA Status:"
          kubectl get hpa --namespace ${K8S_NAMESPACE:-default}

